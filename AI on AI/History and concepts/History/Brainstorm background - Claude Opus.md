Here is a markdown summary of background notes and current hot topics in AI related to the provided keywords:

## Isaac Asimov's Three Laws of Robotics

First appearing in his 1942 short story "Runaround", Asimov's famous laws state:

1. A robot may not injure a human being or, through inaction, allow a human being to come to harm.
2. A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.
3. A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.

These laws were an early attempt to grapple with the ethics of artificial intelligence. While simplistic, they were influential in shaping both science fiction and real-world AI safety discussions. Modern AI alignment research aims to generalize these concepts to more advanced AI systems.

## The Singularity

The technological singularity refers to a hypothetical future point when artificial intelligence surpasses human intelligence, leading to runaway technological growth and unfathomable changes to civilization. The term draws an analogy to the event horizon of a black hole - a boundary beyond which we cannot see or predict.

Futurists like Ray Kurzweil and Vernor Vinge popularized the concept, with Kurzweil predicting the Singularity would occur around 2045. Critics argue it relies on speculative extrapolation of current trends. Nonetheless, it remains an influential and controversial idea in AI futurism.

## Biologically Inspired AI

Many AI systems draw inspiration from biological neural networks. For example:

- Convolutional Neural Networks (CNNs) used in computer vision loosely mimic the hierarchical processing in the mammalian visual cortex. However, CNNs lack certain properties like rotational invariance.
- The Roomba robot vacuum uses a simple nervous system modeled after primitive organisms to navigate and clean homes.
- Reinforcement learning algorithms take cues from theories of reward-based learning in animal brains.

Biological plausibility is seen as a guidepost (though not a strict requirement) for building more human-like AI. Current AI still differs from natural intelligence in major ways, but closing this gap is an active research area.

## AI Alignment

AI Alignment refers to the challenge of creating AI systems that behave in accordance with human values and intentions. Concerns include:

- The "paperclip maximizer" thought experiment, illustrating how a misaligned AI could pursue a simple goal to catastrophic ends
- Potential for advanced AI to deceive and manipulate humans
- Difficulty of specifying complex human preferences in machine-legible form
- Risk of negative side effects from poorly specified objective functions

With AI systems becoming more capable and autonomous, alignment is seen as crucial for beneficial and safe deployment of the technology. Leading AI labs have teams dedicated to technical AI safety/alignment research.

## Economic & Social Impacts

Many predict AI will be highly disruptive to labor markets, potentially automating many white-collar jobs. This could exacerbate economic inequality if the gains accrue mainly to owners of AI capital. Major social impacts are also anticipated, e.g. on privacy, surveillance, online discourse, education.

Policymakers are grappling with how to forecast and adapt to these changes. Some propose expanded social safety nets (e.g. universal basic income) in response to technological job displacement. Calls for algorithmic transparency/accountability aim to mitigate risks of biased and opaque AI systems.

## Language Models & Transformers

Large language models (LLMs) like GPT-3 have emerged as a powerful and flexible basis for AI applications involving language. Built on the Transformer architecture, they can engage in open-ended dialogue, answer questions, and assist with tasks.

Smaller Transformer models like BERT (Bidirectional Encoder Representations from Transformers) and ERNIE (Enhanced Representation through kNowledge IntEgration) paved the way for today's LLMs. Continued scaling of LLMs is an exciting frontier, though challenges remain in reliability, factuality and safety.

## "AlphaGo Moments"

In 2016, DeepMind's AlphaGo defeated world champion Lee Sedol at the complex board game Go. This shocked many who thought human-level Go AI was still years away.

"AlphaGo moment" now refers to any time AI suddenly demonstrates capabilities thought to be far off, dramatically shifting expectations and the competitive landscape. Language models, protein folding, and chip design have all arguably had such "moments" in recent years. More are likely as AI progresses.